<!DOCTYPE HTML>

<!-- Salve, Regina, Mater misericordiæ
vita, dulcedo, et spes nostra, salve.
Ad te clamamus exsules filii Hevæ
Ad te suspiramus, gementes et flentes
in hac lacrimarum valle.
Eia, ergo, advocata nostra, illos tuos
misericordes oculos ad nos converte;
Et Jesum, benedictum fructum ventris tui
nobis post hoc exsilium ostende.
O clemens, O pia, O dulcis Virgo Maria. -->

<html lang="en">
<head>
<title>SQL Code Snippets</title>
<link rel="shortcut icon" type="image/jpg" href="https://raw.githubusercontent.com/mkudija/mkudija.github.io/master/favicon.ico"/>
<meta name="description" content="Matthew Kudija's reading notes.">
<meta name="keywords" content="matthew, kudija, mkudija, catholic, reading, books, note, notes, blog">
<link rel="shortcut icon" href="https://github.com/mkudija/mkudija.github.io/blob/master/favicon.ico">
<link rel="next" href="https://matthewkudija.com/reading.html">
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="../assets/css/main.css" />
<link rel="stylesheet" href="../assets/css/bigfoot-default.css" />
</head>
<body>

<!-- Wrapper -->
<div id="wrapper">

<!-- Main -->
<div id="main">
<div class="inner">
<!-- Header -->
<header id="header">
<a href="https://matthewkudija.com/" class="logo">Matthew Kudija</a>
<div class="header-right">
<a href="https://matthewkudija.com/">Home</a>
<a href="https://matthewkudija.com/about">About</a>
<a href="https://matthewkudija.com/notes/">Notes</a>
<a href="https://matthewkudija.com/reading-notes/">Reading Notes</a>
</div>
</header>

<!-- Content -->

<h1 id="sql-code-snippets">SQL Code Snippets</h1>

<h3 id="create-update-tables">Create &amp; Update Tables</h3>

<p>Create schema:</p>

<pre><code>-- create schema
CREATE SCHEMA my_schema;
</code></pre>

<p>Create table:</p>

<pre><code>-- create table
DROP TABLE IF EXISTS schema.table;
CREATE TABLE schema.table
    AS (
        SELECT * FROM table
    );
</code></pre>

<p>Update table:</p>

<pre><code>DELETE
FROM table
WHERE source = 'a';

INSERT INTO table
SELECT * FROM source_table
</code></pre>

<p>Grant usage:</p>

<pre><code>GRANT USAGE ON SCHEMA &lt;name&gt; TO user;
GRANT SELECT ON ALL TABLES IN SCHEMA &lt;name TO user;

GRANT USAGE ON SCHEMA &lt;name&gt; TO GROUP readonly;
GRANT SELECT ON ALL TABLES IN SCHEMA &lt;name&gt; TO GROUP readonly;
</code></pre>

<pre><code>GRANT USAGE ON [schema] TO mode_analytics;
GRANT SELECT ON [schema.table] TO mode_analytics;
</code></pre>

<h3 id="search-for-column-names">Search for Column Names</h3>

<pre><code>SELECT *  
FROM INFORMATION_SCHEMA.COLUMNS  
WHERE COLUMN_NAME LIKE '%search%'  
ORDER BY TABLE_NAME;
</code></pre>

<p>Big Query:</p>

<pre><code>SELECT DISTINCT * 
FROM `gcp-hopper-etldata-production.warehouse.INFORMATION_SCHEMA.COLUMNS` WHERE column_name LIKE '%session_id%'
</code></pre>

<h3 id="get-tables-in-schema">Get Tables in Schema</h3>

<pre><code>select t.table_name
from information_schema.tables t
where t.table_schema = 'schema_name'  -- put schema name here
      and t.table_type = 'BASE TABLE'
order by t.table_name;
</code></pre>

<h3 id="joins">Joins</h3>

<p><code>on</code></p>

<pre><code>FROM information_schema.tables t
    JOIN information_schema.columns c 
           on c.table_name = t.table_name 
           and c.table_schema = t.table_schema
</code></pre>

<p><code>using</code></p>

<pre><code>FROM information_schema.tables t
    JOIN information_schema.columns c USING(table_name, table_schema)
</code></pre>

<h3 id="find-tables-with-colname-column">Find tables with <code>colName</code> column</h3>

<pre><code>select t.table_schema,
       t.table_name
from information_schema.tables t
inner join information_schema.columns c 
           on c.table_name = t.table_name 
           and c.table_schema = t.table_schema
where c.column_name = 'colName'
      and t.table_schema not in ('information_schema', 'pg_catalog')
      and t.table_type = 'BASE TABLE'
order by t.table_schema;
</code></pre>

<h3 id="unique-items-in-column">Unique items in <strong><code>column</code></strong></h3>

<pre><code>SELECT 
    t.device
FROM 
    database.table t
GROUP BY t.device
</code></pre>

<table>
<thead>
<tr>
  <th></th>
  <th>device</th>
</tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td>"iPhone10,1"</td>
</tr>
<tr>
  <td>2</td>
  <td>"iPhone10,2"</td>
</tr>
<tr>
  <td>3</td>
  <td>"iPhone10,3"</td>
</tr>
<tr>
  <td>4</td>
  <td>"iPhone10,4"</td>
</tr>
<tr>
  <td>5</td>
  <td>"iPhone10,5"</td>
</tr>
</tbody>
</table>

<h3 id="value_count-of-column">value_count of <strong><code>column</code></strong></h3>

<pre><code>SELECT 
    value_count_col
    ,COUNT(id_col) AS value_count
FROM 
    database.table t
GROUP BY 1
ORDER BY 2 DESC
</code></pre>

<pre><code>SELECT 
    t.device
    ,COUNT(t.distance) AS value_count
FROM 
    database.table t
GROUP BY t.device
ORDER BY value_count DESC
</code></pre>

<table>
<thead>
<tr>
  <th></th>
  <th>device</th>
  <th>value_count</th>
</tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td>iPhone10,5</td>
  <td>23832</td>
</tr>
<tr>
  <td>2</td>
  <td>iPhone10,2</td>
  <td>14553</td>
</tr>
<tr>
  <td>3</td>
  <td>iPhone10,4</td>
  <td>3487</td>
</tr>
<tr>
  <td>4</td>
  <td>iPhone10,3</td>
  <td>3078</td>
</tr>
<tr>
  <td>5</td>
  <td>iPhone10,1</td>
  <td>23</td>
</tr>
</tbody>
</table>

<h3 id="npwhere-equivalent-for-cases"><code>np.where</code> equivalent for cases</h3>

<pre><code>CASE
    WHEN t.score BETWEEN 0  AND 24  THEN '0-24'
    WHEN t.score BETWEEN 25 AND 49  THEN '25-49'
    WHEN t.score BETWEEN 50 AND 74  THEN '50-74'
    WHEN t.score BETWEEN 75 AND 100 THEN '75-100'
    ELSE 'OTHER'
END AS score_group
</code></pre>

<h3 id="select-only-firstlast-record-using-rank-over-partition-by">Select only first/last record using <code>RANK() OVER PARTITION BY</code></h3>

<p>In this example, there may be many records for a given <code>user_id</code>, but we only want to select the most recent record for each <code>user_id</code>. Alternatively, we could select the first record by using <code>ASC</code>:</p>

<pre><code>SELECT
    ...
    ...
    FROM(
    SELECT
        ...
    ...
        ,RANK() OVER (PARTITION BY t.user_id ORDER BY t.created_at DESC) AS RANK
        FROM
            database.table AS t
    )
WHERE RANK = 1
</code></pre>

<h3 id="cumulative-value-sum-over-partition-by">Cumulative Value <code>SUM() OVER PARTITION BY</code></h3>

<p>In this value, LTV is a monthly value that we want to show cumulative amount:</p>

<pre><code>SELECT
    ...
    , SUM(ltv_prod)  
      OVER (PARTITION BY policy_effective_month  
      ORDER BY calendar_month ASC ROWS UNBOUNDED PRECEDING) AS ltv_cumulative
    FROM
            database.table AS t
    )
WHERE RANK = 1
</code></pre>

<h3 id="round">Round</h3>

<p><code>ROUND</code> rounds the number, and if you don't want the additional <code>.000</code> you can <code>CAST</code> as an integer:</p>

<p><code>CAST(ROUND(col_name, 0) AS INT) AS col_name_rounded</code></p>

<h3 id="decile">Decile</h3>

<p>Use <code>NTILE</code> function (<a href="https://www.geeksforgeeks.org/ntile-function-in-sql-server/">link</a>):</p>

<pre><code>ntile(20) OVER (PARTITION BY state ORDER BY score) AS score_ntile_state,
</code></pre>

<p>To get actual deciles you can use a <code>CASE</code> statement:</p>

<pre><code>SELECT 
    score_decile, 
    COUNT(score_decile) AS count
FROM (
    SELECT
        *,
        CASE
            WHEN score &lt; 10 THEN '0-9'
            WHEN score &gt; 9 AND score &lt; 20 THEN '10-19'
            WHEN score &gt; 19 AND score &lt; 30 THEN '20-29'
            WHEN score &gt; 29 AND score &lt; 40 THEN '30-39'
            WHEN score &gt; 39 AND score &lt; 50 THEN '40-49'
            WHEN score &gt; 49 AND score &lt; 60 THEN '50-59'
            WHEN score &gt; 59 AND score &lt; 70 THEN '60-69'
            WHEN score &gt; 69 AND score &lt; 80 THEN '70-79'
            WHEN score &gt; 79 AND score &lt; 90 THEN '80-89'
            WHEN score &gt; 89 THEN '90-100'
        END as score_decile
    FROM database.table
)
GROUP BY score_decile
ORDER BY score_decile
</code></pre>

<p>A quick trick is to <code>ROUND</code> with <code>-1</code> to approximate deciles if score is in the range from 0-100. This is not exact as your buckets will be <code>0-5</code>, <code>6-15</code>...<code>86-95</code>, <code>96-100</code> so the first and last buckets will be small, but if you are just comparing between two distributions and care less about the absolute distribution, this may be an easy trick.</p>

<pre><code>SELECT 
    score_decile_approx, 
    COUNT(score_decile_approx) AS count
FROM (
    SELECT
        *,
        ROUND(score, -1) AS score_decile_approx
    FROM database.table
)
GROUP BY score_decile_approx
ORDER BY score_decile_approx
</code></pre>

<p>Finally, we may want the <em>rate</em> rather than the count, which we can get with the <code>RATIO_TO_REPORT(count) OVER () AS rate</code> command. This gives <code>rate</code> for each row as a fraction of the sum of count <code>count</code> column.</p>

<pre><code>SELECT 
    score_decile_approx, 
    COUNT(score_decile_approx) AS count,
    RATIO_TO_REPORT(count) OVER () AS rate
FROM (
    SELECT
        *,
        ROUND(unmapped_score, -1) AS score_decile_approx
    FROM database.table

)
GROUP BY score_decile_approx
ORDER BY score_decile_approx
</code></pre>

<h3 id="equal-size-buckets">Equal Size Buckets</h3>

<pre><code>WITH buckets AS (
    SELECT
        value
        , NTILE(5) OVER (ORDER BY value ASC) AS value_bucket
    FROM table
)

SELECT 
    value_bucket
    , MIN(value) AS bucket_lower
    , MAX(value) AS bucket_upper
FROM buckets
GROUP BY 1
ORDER BY 1
</code></pre>

<p>see also <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/mathematical_functions#range_bucket">Bigquery RANGE_BUCKET()</a> to assign values rather than case</p>

<h3 id="ratio-over-groupby">Ratio over groupby</h3>

<p>Above we use the <code>RATIO_TO_REPORT</code> command to get a ratio rather than count. If we want a time series showing percent, and it is groupe by time (week, month, etc.), this is how you get a rate for each group rather than the whole table:</p>

<pre><code>    RATIO_TO_REPORT(account_count) OVER(PARTITION BY DATE_TRUNC('month', account_timestamp))
</code></pre>

<p>or</p>

<pre><code>    DATE_TRUNC('quarter', account_timestamp) AS x,
    RATIO_TO_REPORT(account_count) OVER(PARTITION BY x)
</code></pre>

<h3 id="number-of-items-and-most-recent-in-table">Number of items and most recent in table</h3>

<pre><code>SELECT 
    COUNT(*), 
    MAX(created_at) 
FROM 
    database.table
</code></pre>

<h3 id="rolling-mean">Rolling Mean</h3>

<pre><code>SELECT 
    DATE_TRUNC('day', profile_timestamp) AS x,
    COUNT(DISTINCT account_id) AS new_user_count,
    AVG(new_user_count) OVER (ORDER BY x ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS count_rolling
FROM 
    database.table
</code></pre>

<h3 id="percent-change">Percent Change</h3>

<p>Display the <code>%</code> symbol:</p>

<pre><code>    CONCAT(ROUND((edw_PLE_months_30_4 - edw_PLE_months_30) / edw_PLE_months_30 * 100, 2),'\%') AS percent_diff
</code></pre>

<h3 id="percent-of-total">Percent of Total</h3>

<pre><code>earned_premium/SUM(earned_premium) OVER () as percent_of_total
</code></pre>

<p>or</p>

<pre><code>RATIO_TO_REPORT(earned_premium) OVER () AS percent_of_total
</code></pre>

<h3 id="optimize-query">Optimize Query</h3>

<p>If you run the query with <code>EXPLAIN</code> on top it will give you the query plan and how costly each step is.</p>

<h3 id="pivot-table">Pivot Table</h3>

<p>You can pivot, but you need to manually specify the column values:</p>

<pre><code>WITH pre AS (  
    SELECT state  
         , amount  
         , month  
    FROM state_mgt.planned_rate  
)  
SELECT *  
FROM pre PIVOT(SUM(amount) FOR MONTH IN ('2022-02-28','2022-03-30','2022-04-30'));
</code></pre>

<h3 id="most-recent-month-end-date-prior-month-end">Most Recent Month-End Date (Prior Month End)</h3>

<pre><code>SELECT DATEADD(DAY, -1, DATE_TRUNC('month', CURRENT_DATE - 1)) AS most_recent_month_end_date
</code></pre>

<p>BigQuery</p>

<pre><code>SELECT DATE_SUB(DATE_TRUNC(CURRENT_DATE(), MONTH), INTERVAL 1 DAY)
</code></pre>

<h3 id="month-start-date">Month Start Date</h3>

<pre><code>SELECT DATE_TRUNC(CURRENT_DATE,MONTH) AS calendar_month
</code></pre>

<h3 id="view-tables-in-schema">View Tables in Schema</h3>

<pre><code>-- view tables in schema
SELECT t.table_name
FROM information_schema.tables t
WHERE t.table_schema = 'schema' -- put schema name here
    AND t.table_type = 'BASE TABLE'
ORDER BY t.table_name;
</code></pre>

<h3 id="lag-offset-column-by-n-rows">Lag (Offset column by n rows)</h3>

<pre><code>SELECT
    col
    LAG(col, 1) OVER (ORDER BY calendar_month ASC) AS col_lag_7
</code></pre>

<h3 id="development-months-and-terms">Development Months and Terms</h3>

<p><code>dev_mo</code> starts at 0, <code>term</code> starts at 1:</p>

<pre><code>, DATEDIFF('month', policy_effective_month, calendar_month) AS dev_month  
, dev_month / 6 + 1 AS term
</code></pre>

<h2 id="dates">Dates</h2>

<h3 id="last-7-days-of-data">Last 7 days of data</h3>

<pre><code>SELECT 
    *
FROM 
    database.table t
WHERE
    t.created_at &gt; GETDATE() - INTERVAL '7 days'
</code></pre>

<h3 id="date_diff">DATE_DIFF</h3>

<pre><code>DATE_DIFF('month', start_month, calendar_month) AS age
</code></pre>

<h3 id="date_trunc">DATE_TRUNC</h3>

<p>To transform a timestamp into weekly or daily etc. data use <code>DATE_TRUNC()</code>. Available <code>datepart</code>s are listed <a href="http://www.postgresqltutorial.com/postgresql-date_trunc/">here</a>.</p>

<p>GCP/BQ</p>

<pre><code>DATE_TRUNC(timestamp, WEEK) AS week
</code></pre>

<pre><code>SELECT
    DATE_TRUNC('day', timestamp) AS day
</code></pre>

<p>or </p>

<pre><code>SELECT
    DATE_TRUNC('week', timestamp) AS week
</code></pre>

<p>or</p>

<pre><code>SELECT
    DATE_TRUNC('month', timestamp) AS month
</code></pre>

<p>or</p>

<pre><code>SELECT
    DATE_TRUNC('quarter', timestamp) AS quarter
</code></pre>

<h3 id="get-month-offset-from-current-date-also-end-of-month">Get month offset from current date (also end of month)</h3>

<ul>
<li><code>CURRENT_DATE</code> to get current date</li>
<li><code>DATEADD</code> to offset by a number of months</li>
<li><code>LAST_DAY</code> to get last day of month</li>
</ul>

<pre><code>policy_inception_month = LAST_DAY(DATEADD(MM,-6, CURRENT_DATE))
</code></pre>

<p><em>or</em></p>

<pre><code>WHERE prediction_date = LAST_DAY(DATE_ADD('month', -1, CURRENT_DATE))
</code></pre>

<h3 id="current-date">Current Date</h3>

<pre><code>SELECT LEFT(GETDATE(),10)
</code></pre>

<h3 id="select-except-columns">Select * Except Columns</h3>

<pre><code>SELECT
joined.*,
air.* EXCEPT(purchase_date,purchase_week,purchase_month),
hotel.* EXCEPT(purchase_date,purchase_week,purchase_month),
</code></pre>

<p>GCP example: <code>flex_dashboard_july2022</code></p>

<h3 id="array-of-dates">Array of Dates</h3>

<pre><code>SELECT m AS calendar_month
FROM UNNEST(GENERATE_DATE_ARRAY('2023-01-01', CURRENT_DATE(), INTERVAL 1 MONTH)) AS m
</code></pre>

<h3 id="z-score-anomaly-detection">Z-score Anomaly Detection</h3>

<p><em>ref: <a href="https://hakibenita.com/sql-anomaly-detection">Simple Anomaly Detection Using Plain SQL | Haki Benita</a></em></p>

<pre><code>WITH data AS (
    SELECT
    event_date
    , dim1
    , dim2
    , value
  FROM table
  GROUP BY 1,2,3
)

, averages AS (
  SELECT 
    *
    , ROUND(AVG(value) OVER (PARTITION BY dim1, dim2 ORDER BY event_date ROWS BETWEEN 21 PRECEDING AND 1 PRECEDING)) AS value_avg
    , ROUND(STDDEV(value) OVER (PARTITION BY dim1, dim2 ORDER BY event_date ROWS BETWEEN 21 PRECEDING AND 1 PRECEDING),3) AS value_std
  FROM data
)

, thresholds AS (
  SELECT
    3.0 AS z_thresh -- zscore anomaly threshold 
)

, zscores AS (
  SELECT 
    *
    , (value - value_avg) / NULLIF(value_std, 0) as value_zscore
    , (exercise_count - count_avg) / NULLIF(count_std, 0) as count_zscore
    , (cpe - cpe_avg) / NULLIF(cpe_std, 0) as cpe_zscore
    , (SELECT z_thresh FROM thresholds) AS z_thresh
  FROM averages
)

, bounds AS (
  SELECT 
    *
    , value_avg + value_std * z_thresh AS value_bound_upper
    , value_avg - value_std * z_thresh AS value_bound_lower
  FROM zscores
)

, anomalies AS (
  SELECT 
    *
    , CASE WHEN value_zscore &lt; -z_thresh OR value_zscore &gt; z_thresh THEN 1 ELSE 0 END AS value_anomaly
  FROM bounds
)

SELECT *
FROM anomalies
WHERE event_date BETWEEN DATE_ADD(CURRENT_DATE(), INTERVAL -120 DAY) AND CURRENT_DATE()
ORDER BY 1 DESC,2,3
</code></pre>

<h3 id="select-except">SELECT EXCEPT</h3>

<pre><code>SELECT
    * EXCEPT(col1, col2)
</code></pre>

<h3 id="30-days-ago">30 Days Ago</h3>

<pre><code>DATE_ADD(CURRENT_DATE(), INTERVAL -30 DAY)
</code></pre>

<h2 id="resources">Resources</h2>

<ul>
<li><a href="https://sqlbolt.com/">SQLBolt - Learn SQL</a></li>
<li><a href="https://sqlzoo.net/wiki/SQL_Tutorial">SQLZOO</a></li>
<li><a href="https://www.sisense.com/blog/sql-query-order-of-operations/">SQL Query Order of Execution</a></li>
<li><a href="https://www.pearson.com/store/p/database-design-for-mere-mortals-25th-anniversary-edition/P100002994160/9780136788041">Database Design for Mere Mortals</a></li>
<li><a href="https://mystery.knightlab.com/">The SQL Murder Mystery</a>
<ul>
<li>Congrats, you found the brains behind the murder! Everyone in SQL City hails you as the greatest SQL detective of all time. Time to break out the champagne!</li>
</ul></li>
<li><a href="https://github.com/dcmoura/spyql">spyql: Query data on the command line with SQL-like SELECTs powered by Python expressions</a></li>
<li><em><a href="https://github.com/mkudija/mkudija.github.io/tree/master/reading-notes/_md/~The Data Warehouse Toolkit.md">The Data Warehouse Toolkit</a></em></li>
</ul>

<hr />

<p>Created: <a href="../reading-notes/2019-06-25-Tue.html">2019-06-25-Tue</a><br />
Updated: 2024-07-03-Wed</p>


</div>
</div>
</div>

<!-- Scripts -->
<!-- Script: Latex -->
<!-- Script: Mermaid -->
<script src="../assets/js/jquery.min.js"></script>
<script type="text/javascript" src="../assets/js/bigfoot.js"></script>
<script type="text/javascript">
$.bigfoot (
{

}
);
</script>
</body>
<hr>
<footer id="footer" align="center">
<center>
<img src="../images/kudija_family_shield.png" width=100px>
<p class="copyright">&copy; 2005<script>new Date().getFullYear()>2005&&document.write("–"+new Date().getFullYear());</script> Matthew Kudija • <a href="https://github.com/mkudija/mkudija.github.io/" target="_blank">Source</a></p>
</center>
</footer>
</html>
